# ğŸš€ KSP RL Agents

**Reinforcement Learning agents trained to launch, hover, and land rockets inside Kerbal Space Program (KSP).**

---

## ğŸŒŒ Overview

This project explores **autonomous rocket control** in KSP using **Reinforcement Learning (RL)**.
Agents are trained via [kRPC](https://krpc.github.io/krpc/) to interact with KSP in real-time, learning to:

* ğŸ”¼ **Launch Agent** â†’ perform smooth vertical ascents
* ğŸ›° **Hover Agent** â†’ stabilize around a target altitude
* ğŸ”½ **Landing Agent** â†’ execute powered landings with minimal error

All agents are built using **Stable-Baselines3 (PPO)**, with custom KSP environments exposing physics and telemetry.

---

## ğŸ“‚ Repository Structure

```
KSP-RL-Agents/
â”‚
â”œâ”€â”€ Helper/                    # Utility functions and plotting scripts
â”‚   â””â”€â”€ plotting.py
|   â””â”€â”€ flight_recorder
|       â””â”€â”€ flight_recorder.py
|       â””â”€â”€ plot.py
â”‚
â”œâ”€â”€ KSP_Hover_Agent/           # Hover agent training & testing
â”‚   â”œâ”€â”€ hover_agent.py         # PPO hover agent
â”‚   â”œâ”€â”€ hover_test.py          # Test scripts for hover agent
â”‚   â””â”€â”€ ksp_hover_env.py       # Custom KSP hover environment
â”‚
â”œâ”€â”€ KSP_Landing_Agent/         # Landing agent training & testing
â”‚   â”œâ”€â”€ ksp_land_env.py        # Custom KSP landing environment
â”‚   â”œâ”€â”€ test_land_agent.py     # Evaluate trained landing agent
â”‚   â””â”€â”€ train_land_agent.py    # Training loop for landing agent
â”‚
â”œâ”€â”€ KSP_Launching_Agent/       # Launching agent training & testing
â”‚   â”œâ”€â”€ agent.py               # PPO launch agent
â”‚   â”œâ”€â”€ ksp_env.py             # Custom KSP launch environment
â”‚   â””â”€â”€ test.py                # Evaluate trained launch agent
â”‚
â”œâ”€â”€ showcase/                  # Demos and visualizations
â”‚   â”œâ”€â”€ earth_1.11.mp4         # Demo video: Launching agent
â”‚   â”œâ”€â”€ moon_1.11.mp4          # Demo video: Landing agent
â”‚   â””â”€â”€ flight_dashboard.png
â”‚
â”œâ”€â”€ requirement.txt            # Python dependencies
â””â”€â”€ README.md                  # Project description (this file)
```

---

## âš™ï¸ Installation

1. **Install KSP**

   * Tested with KSP1

2. **Install kRPC mod**

   * Place in `GameData/`, start the server inside KSP

3. **Set up Python environment**

   ```bash
   git clone https://github.com/Weirdnemo/KSP-RL-Agents.git
   cd KSP-RL-Agents
   pip install -r requirement.txt
   ```

Requirements include:

* `stable-baselines3`
* `gym`
* `krpc`
* `numpy`

---

## ğŸ§  How It Works

* **Environment:** Custom Gym wrappers around KSP via kRPC (altitude, velocity, orientation, fuel states)
* **Agent:** PPO learns throttle, pitch, and burn profiles
* **Rewards:** Shaped to encourage stable control and minimize error

| Agent     | Goal                                | Reward Signal          |
| --------- | ----------------------------------- | ---------------------- |
| Launching | Reach target altitude efficiently   | Time & fuel efficiency |
| Hovering  | Hold altitude without overshoot     | Distance from setpoint |
| Landing   | Touch down safely, minimal velocity | Smoothness + precision |

---

## ğŸ¥ Demos

*(See `/showcase/` for full-resolution videos and captures)*

---

## ğŸ“Š Results

* Trained over **tens of thousands of episodes**
* Agents converge to **stable, repeatable behaviors** in all three tasks
* Performance beats naive scripted control (PID-only baselines)

---

## ğŸ”® Next Steps

* Multi-objective training: launch â†’ hover â†’ land in a single trajectory
* More robust environments (randomized gravity, payloads, wind)
* Compare PPO with SAC, TD3, A2C
* Long-term: full **autonomous orbital insertion** in KSP

---

## ğŸ· Credits

* Built by [Weirdnemo](https://github.com/Weirdnemo) over 2â€“3 months
* Powered by [Stable-Baselines3](https://github.com/DLR-RM/stable-baselines3) + [kRPC](https://krpc.github.io/krpc/)

---

## ğŸ“œ License

Open source under your preferred license (default: MIT).
